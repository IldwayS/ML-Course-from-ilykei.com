{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install mlcrate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9sFiR2e3exe",
        "outputId": "3e2aa6fe-73ee-4d6c-c401-38cb28cf5499"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mlcrate in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mlcrate) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from mlcrate) (2.2.2)\n",
            "Requirement already satisfied: pathos in /usr/local/lib/python3.11/dist-packages (from mlcrate) (0.3.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from mlcrate) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->mlcrate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->mlcrate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->mlcrate) (2025.2)\n",
            "Requirement already satisfied: ppft>=1.7.7 in /usr/local/lib/python3.11/dist-packages (from pathos->mlcrate) (1.7.7)\n",
            "Requirement already satisfied: dill>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pathos->mlcrate) (0.4.0)\n",
            "Requirement already satisfied: pox>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from pathos->mlcrate) (0.3.6)\n",
            "Requirement already satisfied: multiprocess>=0.70.18 in /usr/local/lib/python3.11/dist-packages (from pathos->mlcrate) (0.70.18)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->mlcrate) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "#import gc\n",
        "\n",
        "import mlcrate as mlc\n",
        "import pickle as pkl\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (Embedding, Dense, Flatten, Concatenate,\n",
        "                                     Dot, Reshape, Add, Subtract, BatchNormalization)\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "embedding_reg = 0.0002\n",
        "kernel_reg = 0.1\n",
        "out_dim=2\n",
        "weight_matrix = np.arange(12).reshape((-1,2))\n",
        "\n",
        "def get_embed(x_input, x_size, out_dim,test_weights=False):\n",
        "    # x_input is index of input (either user or item)\n",
        "    # x_size is length of vocabulary (e.g. total number of users or items)\n",
        "    # test_weights is a demo flag to show results with predefined weights\n",
        "    # out_dim is size of embedding vectors\n",
        "    if x_size > 0: #category\n",
        "        if test_weights & (out_dim<=2):\n",
        "            embed = Embedding(0, out_dim, input_length=1,\n",
        "                          weights=[weight_matrix[:x_size,:out_dim]],\n",
        "                          embeddings_regularizer=l2(embedding_reg))(x_input)\n",
        "        else:\n",
        "            embed = Embedding(x_size, out_dim, input_length=1,\n",
        "                              embeddings_regularizer=l2(embedding_reg))(x_input)\n",
        "        embed = Flatten()(embed)\n",
        "    else:\n",
        "        embed = Dense(out_dim, kernel_regularizer=l2(embedding_reg))(x_input)\n",
        "    return embed\n",
        "def build_model(f_size):\n",
        "    k_latent = 3\n",
        "    kernel_reg = 0.01\n",
        "\n",
        "    input_x = [Input(shape=(1,)) for _ in range(len(f_size))]\n",
        "    lin_terms = [get_embed(x, size, 1) for (x, size) in zip(input_x, f_size)]\n",
        "    factors = [get_embed(x, size, k_latent) for (x, size) in zip(input_x, f_size)]\n",
        "\n",
        "    # Sum of factors\n",
        "    s = Add()(factors)\n",
        "    diffs = [Subtract()([s, x]) for x in factors]\n",
        "    dots = [Dot(axes=1)([d, x]) for d, x in zip(diffs, factors)]\n",
        "\n",
        "    # Concatenate linear terms and dot products\n",
        "    x = Concatenate()(lin_terms + dots)\n",
        "\n",
        "    # BatchNormalization expects a fixed feature size\n",
        "    x = Dense(4, activation='linear')(x)  # Aligning features to a fixed size\n",
        "    x = BatchNormalization()(x)          # Batch normalization applied to a fixed-size tensor\n",
        "\n",
        "    # Final output layer\n",
        "    output = Dense(1, activation='relu', kernel_regularizer=l2(kernel_reg))(x)\n",
        "\n",
        "    model = Model(inputs=input_x, outputs=[output])\n",
        "    model.compile(optimizer=Adam(clipnorm=0.01, learning_rate=0.001),\n",
        "                  loss='mean_squared_error')\n",
        "    return model\n",
        "\n",
        "\n",
        "train_df = pd.read_csv(\"train_sample.csv\")\n",
        "test_df = pd.read_csv(\"test_sample.csv\")\n",
        "\n",
        "X_train = train_df[['feature_0', 'feature_1', 'feature_2']].values\n",
        "y_train = train_df['target'].values\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "X_test = test_df[['feature_0', 'feature_1', 'feature_2']].values\n",
        "\n",
        "X_train_list = np.hsplit(X_train, 3)\n",
        "X_test_list = np.hsplit(X_test, 3)\n",
        "X_val_list = np.hsplit(X_val,3)\n",
        "features = ['feature0', \"feature1\", \"feature2\"]\n",
        "f_size = [int(np.max(X_train_list[i])) + 1 for i in range(3)]\n",
        "print(X_train_list)\n",
        "n_epochs = 100\n",
        "\n",
        "batch_size = 77\n",
        "print('Batch size: ',batch_size)\n",
        "model = build_model(f_size)\n",
        "earlystopper = EarlyStopping(patience=2, verbose=0)\n",
        "model.fit(X_train_list, y_train, epochs=n_epochs, batch_size=batch_size, verbose=0,\n",
        "          validation_data=(X_val_list, y_val))\n",
        "best_epoch = earlystopper.stopped_epoch\n",
        "print(best_epoch)\n",
        "print('RMSE',model.evaluate(X_val_list, y_val,\n",
        "                            batch_size=batch_size,verbose=0)**0.5)\n",
        "prediction = model.predict(X_test_list)\n",
        "sub = pd.read_csv('test_sample.csv',usecols=['ID'])\n",
        "sub['target'] = prediction\n",
        "sub.to_csv('submission.csv',index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCh9AKoh3bKa",
        "outputId": "6850953a-09d2-421d-b9f5-9d438ef30f85"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[44],\n",
            "       [23],\n",
            "       [39],\n",
            "       ...,\n",
            "       [32],\n",
            "       [18],\n",
            "       [30]]), array([[24],\n",
            "       [23],\n",
            "       [ 7],\n",
            "       ...,\n",
            "       [17],\n",
            "       [12],\n",
            "       [31]]), array([[10],\n",
            "       [ 6],\n",
            "       [37],\n",
            "       ...,\n",
            "       [ 1],\n",
            "       [ 9],\n",
            "       [ 3]])]\n",
            "Batch size:  77\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "RMSE 0.2726338292606943\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n"
          ]
        }
      ]
    }
  ]
}